{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIWritter",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KVdBBM3q-0KM_q5Flr3hM9yHs41vcPW8",
      "authorship_tag": "ABX9TyO+23O9+LTuiO66GjKcuZVz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZhangEliot/EZYJAWritter/blob/master/AIWritter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DiTyERIa5Xi",
        "colab_type": "text"
      },
      "source": [
        "**<font color='blue'>EZYJAWritter -- 一个自动写渔家傲词的LSTM</font>**</br>\n",
        "<font color='orange'>按顺序运行就好了</br>\n",
        "启发语句可能会作为开头</br>\n",
        "也可能不会~</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEclCU04gqvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "cellView": "form",
        "outputId": "67bf3e48-46ef-4898-91d1-cc2968bd4f68"
      },
      "source": [
        "#@title <font color='hotpink'>运行这个可以看看分配到的是啥GPU，也可以不运行</font> { vertical-output: true }\n",
        "!nvidia-smi"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  9 11:56:31 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    27W /  70W |   2657MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKKJuTWnWGXi",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title <font color=red><--- 点这儿运行</font> { vertical-output: true }\n",
        "#@markdown <font color=orange><b>先运行这个！下载预先训练好的模型！</br>不然运行不起来！（废话。。。</b></font>\n",
        "!git clone https://github.com/ZhangEliot/EZYJAWritter.git\n",
        "!7z x EZYJAWritter/yja-166.7z.001 -r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqOXaJUdyIPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "cellView": "form",
        "outputId": "6c29f97b-948b-4ff1-a276-4de42158b9da"
      },
      "source": [
        "#@title <font color=red><--- 点这儿运行</font> { vertical-output: true }\n",
        "#@markdown <font color=hotpink><b>提供不多于7个汉字的启发语句，然后即可运行！</b></font>\n",
        "import logging, os\n",
        "logging.disable(logging.WARNING)\n",
        "import sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "启发语句 = '雪花飘飘' #@param {type: \"string\"} \n",
        "#@markdown ---\n",
        "MODEL_PATH = 'yja-166'\n",
        "CHARSET_PATH = 'EZYJAWritter/GB2312.txt'\n",
        "MAXLEN = 28\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0, size=1):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(size, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def ChangePouncture(s, p='，'):\n",
        "    return s[:-1] + p\n",
        "\n",
        "\n",
        "def PrettyLook(words):\n",
        "    words[0] = ChangePouncture(words[0])\n",
        "    words[1] = ChangePouncture(words[1])\n",
        "    words[3] = ChangePouncture(words[3])\n",
        "    words[4] = ChangePouncture(words[4], '。\\n')\n",
        "    words[5] = ChangePouncture(words[5])\n",
        "    words[6] = ChangePouncture(words[6])\n",
        "    words[8] = ChangePouncture(words[8])\n",
        "    return ''.join(words)\n",
        "\n",
        "\n",
        "def WritePoem(sentence):\n",
        "    # Init\n",
        "    ezWritter = load_model(MODEL_PATH)\n",
        "    words = []\n",
        "    rythmic = [8, 8, 8, 4, 8, 8, 8, 8, 4, 8]\n",
        "    diversity = [0.2, 0.4, 0.6, 0.8, 1.0, 1.2]\n",
        "    # Load charset\n",
        "    with open(CHARSET_PATH, encoding='UTF-8') as f:\n",
        "        text = f.read()\n",
        "    chars = sorted(list(set(text)))\n",
        "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "    ###\n",
        "    try:\n",
        "        word = sentence\n",
        "        temperature = diversity[np.random.randint(0, 6)]\n",
        "        print('正在构思......')\n",
        "        for i in range(1000):\n",
        "            x_pred = np.zeros((1, len(sentence), len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1\n",
        "\n",
        "            preds = ezWritter.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds,\n",
        "                                temperature,\n",
        "                                np.random.randint(10, 21))\n",
        "            next_char = indices_char[next_index]\n",
        "            word += next_char\n",
        "            if (next_char == '。'):\n",
        "                if (len(word) == rythmic[len(words)]):\n",
        "                    words.append(word)\n",
        "                else:\n",
        "                    word = ''\n",
        "            if (next_char == '\\n'):\n",
        "                word = ''\n",
        "            if (len(words) == 10):\n",
        "                return PrettyLook(words)\n",
        "            sentence = sentence[1:] + \\\n",
        "                next_char if len(sentence) >= MAXLEN else sentence + next_char\n",
        "    except Exception:\n",
        "        return '请换句启发语再试！'\n",
        "    return '请换句启发语再试！'\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(WritePoem(启发语句[:28]))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "正在构思......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "雪花飘飘归一际，天今不是长门赋，日半嫩来花枕好。君林许，玉朝一念声千侣。\n",
            "绿索清旗双彩水，千舟须地归年蕊，羌管悠桥行满浪。心窈窕，青声衰到相须傲。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jFlC3s0NSCN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Lv.??? 训练模型用的 { vertical-output: true }\n",
        "#@markdown <b><font color='red'>仅供EliotZhang使用！</font></br>(bushi，只是需要配置GoogleDrive工作环境</b></br>\n",
        "#@markdown <b>懒得写介绍了，看代码自己弄吧~</br>也就几个文件夹的事儿</b></br>\n",
        "#@markdown <b>实在不行可以看看我的工作空间是啥样的：</br>[传送门](https://drive.google.com/drive/folders/1-x8qzErCO_E8TMuGtxiPkhUuQl5iBj1d?usp=sharing)</b>\n",
        "\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "maxlen =   28#@param {type: \"number\"}\n",
        "step =   1#@param {type: \"number\"}\n",
        "批大小 = 2048 #@param {type: \"number\"}\n",
        "总迭代数 = 1024 #@param {type: \"number\"}\n",
        "学习率 = 0.001 #@param {type: \"number\"}\n",
        "编码 = \"GB2312\" #@param [\"GB2312\", \"pq\"]\n",
        "是否使用训练集作为编码 = False #@param {type: \"boolean\"}\n",
        "训练集 = \"yja\"  #@param [\"nl\", \"ypzs\", \"dqol\", \"tzsy\", \"zj\", \"yja\"]\n",
        "是否继续上一次的训练 = False  #@param {type: \"boolean\"}\n",
        "模型路径 = \"/content/drive/My Drive/AIWritter/Models/yja-004-5.9229\" #@param {type: \"string\"}\n",
        "训练时最大书写长度 = 100 #@param {type: \"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "path = f'/content/drive/My Drive/AIWritter/Books/{训练集}.txt'\n",
        "checkpoint_path = f'/content/drive/My Drive/AIWritter/Models/{训练集}'+'-{epoch:03d}-{loss:.4f}'\n",
        "with open(path, encoding='UTF-8') as f:\n",
        "    text = f.read()\n",
        "print('text length:', len(text))\n",
        "\n",
        "path = f'/content/drive/My Drive/AIWritter/{编码}.txt' if not 是否使用训练集作为编码 else path\n",
        "with open(path, encoding='UTF-8') as f:\n",
        "    charset = f.read()\n",
        "chars = sorted(list(set(charset)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "for char in text:\n",
        "    if not char in char_indices.keys():\n",
        "        char_indices[char] = len(chars)\n",
        "        indices_char[len(chars)] = char\n",
        "        chars.append(char)\n",
        "        with open(path, 'a') as f:\n",
        "            f.write(char)\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "# build the model: LSTM\n",
        "try:\n",
        "    if (not 是否继续上一次的训练):\n",
        "        raise Exception('不需要载入模型')\n",
        "    model = load_model(模型路径)\n",
        "except Exception as e:\n",
        "    print(repr(e))\n",
        "    print('Build model...')\n",
        "    model = Sequential(name='EZWritter')\n",
        "    model.add(LSTM(512, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
        "    model.add(LSTM(1024, return_sequences=True))\n",
        "    model.add(LSTM(2048))\n",
        "    model.summary()\n",
        "    model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "    optimizer = RMSprop(learning_rate=学习率)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# show model structure\n",
        "model.summary()\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    diversity = np.random.randint(1, 3) / 10.0\n",
        "    print('----- diversity:', diversity)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(训练时最大书写长度):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=False,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=批大小,\n",
        "          epochs=总迭代数,\n",
        "          callbacks=[model_checkpoint_callback, print_callback])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}